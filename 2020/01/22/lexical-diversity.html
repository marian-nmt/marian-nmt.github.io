<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->

  <head>
  <title>
    
    Marian :: Is MT really lexically less diverse than human translation?
    
  </title>
  <!-- Meta -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="This blog post describes my journey into the rabbit hole that is lexical diversity of machine translation outputs. We take a look at lexical diversity of WMT...">

  <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
  <!-- Global CSS -->
  <link rel="stylesheet" href="/assets/plugins/bootstrap/css/bootstrap.min.css">
  <!-- Plugins CSS -->
  <link rel="stylesheet" href="/assets/plugins/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/pygments/github.css">

  <!-- Theme CSS -->
  <link id="theme-style" rel="stylesheet" href="/assets/css/styles.css">
  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <link rel="stylesheet" href="/assets/plugins/github-fork-ribbon-css/gh-fork-ribbon.css" />
  <!--[if lt IE 9]>
    <link rel="stylesheet" href="/assets/plugins/github-fork-ribbon-css/gh-fork-ribbon.ie.css" />
  <![endif]-->

  

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109819276-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-109819276-1');
</script>

  

</head>


  <body class="body-blue">
    <a class="github-fork-ribbon" href="https://github.com/marian-nmt/marian" title="Fork me on GitHub">Fork me on GitHub</a>

    <div class="page-wrapper">

    <header id="header" class="header">
  <div class="container">
    <div class="branding">
      <h1 class="logo">
        <a href="/">
          <span aria-hidden="true" class="icon_documents_alt icon"></span>
          <span class="text-highlight">Marian</span><span class="text-bold">NMT</span>
        </a>
      </h1>
      <p class="description">Fast Neural Machine Translation in C++</p>
    </div><!--//branding-->

    <ol class="breadcrumb">


 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
 <li>
   <a class="page-link" href="/quickstart/">Quick start</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/features/">Features &amp; Benchmarks</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/docs/">Documentation</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/examples/">Examples</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/faq">FAQ</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/publications/">Publications</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/blog">Blog</a>
 </li>
 

</ol>


  </div><!--//container-->
</header><!--//header-->


    <div class="doc-wrapper">
      <div class="container">

        <div id="doc-header" class="doc-header text-center">
          <h1 class="doc-title">
            Is MT really lexically less diverse than human translation?
          </h1>
          <div class="meta">
            <i class="fa fa-clock-o"></i>
            22 January 2020  :: Marcin Junczys-Dowmunt 
          </div>
        </div><!--//doc-header-->

        <div class="doc-body">
          <div class="doc-content">
            <div class="content-inner">

              <h2 id="what-got-me-interested-in-lexical-diversity-of-mt-outputs">What got me interested in lexical diversity of MT outputs?</h2>

<p>This blog post describes my journey into the rabbit hole that is lexical diversity of machine translation outputs. I got interested in the topic after attending MT Summit 2019 in Dublin last year and listening to two intriguing talks, one by Eva Vanmassenhove (<a href="https://www.aclweb.org/anthology/W19-6622/" target="_blank">Vanmassenhove et al. 2019</a> ) and one by Antonio Toral (<a href="https://www.aclweb.org/anthology/W19-6627/" target="_blank">Toral 2019</a>)  – which then went on to win the best paper award at that conference for his talk.</p>

<p>Both papers conclude – among other observations – that machine translation outputs demonstrate lower lexical diversity as measured by various existing metrics than human translations. Machine translation and human translations in turn demonstrate lower lexical diversity than human-written text that was naturally composed in the same target language. I like both papers a lot for the approaches they take in analyzing their data, but both have problems in their choice of analyzed MT systems and modeling decisions.  <a href="https://www.aclweb.org/anthology/W19-6622/" target="_blank">Vanmassenhove et al. (2019)</a> create MT systems that due to smaller data and lack of subword segmentation are likely to show lower lexical diversity. <a href="https://www.aclweb.org/anthology/W19-6627/" target="_blank">Toral (2019)</a> includes a number of state-of-the-art systems (at their time of creation), but in my opinion too few to be able to infer that MT is generally lexically less diverse than human translations (the main focus of that work is Post-Editese though). 
<a href="https://www.aclweb.org/anthology/W19-6622/" target="_blank">Vanmassenhove et al. (2019)</a>  look at two translation directions (en-fr, en-es) with small training corpora (ca. 1 million sentences) and three MT flavors (SMT, NMT-RNN, NMT-Transformer) with and without back-translation, 12 systems altogether.</p>

<p>Correction: I wrote in an earlier version of the post that <a href="https://www.aclweb.org/anthology/W19-6622/" target="_blank">Vanmassenhove et al. (2019)</a> used 100K sentences of training data; that is incorrect. I looked at the wrong table and mixed up vocabulary size and training data size.</p>

<p><a href="https://www.aclweb.org/anthology/W19-6627/" target="_blank">Toral (2019)</a> compares 18 systems on 6 language pairs, one of them can be considered close to current state-of-the-art (zh-en). Both use type-token ration (TTR) as one of their metrics. I will do the same in this post. Type-token ratio is just the number of unique lexical items in the text divided by the number of running tokens. For data sets of the same length this is probably a reasonable diversity measure. In my repository I also have code for using MTLD, but I saw no strongly differing results while MTLD feels unreasonably complicated and numerically ill-defined (+inf for perfect LD?).</p>

<p>The research questions in these two papers sparked my interest, but I am mostly curious if lexical diversity (LD) – this apparently easily measurable property – can be used for something practical. If LD indeed reliably separates natural text from human translationese and human translationese from machine translationese as these works suggest then there might be applications to identifying machine-translated content in large parallel corpora or at least the directionality of human translations (looking at gradients of LD on both sides compared to other document pairs with gradients pointing in other directions). Or we might be able to subselect training corpora to have larger LD, potentially increasing the LD of our MT systems if that is actually a desired property. To get a better feeling for LD, let’s go large-scale!</p>

<h2 id="wmt-or-it-didnt-happen">WMT or it didn’t happen!</h2>

<p>I have been vocally critical of work that uses artificially small data for testing research hypotheses. By “artificially small” I mean cases where lots of data is actually available, but only a small corpus is chosen for experiments with little to no justification. I am also of the opinion that questions about capabilities of MT have to be measured on capable MT models. Toy models trained on toy data result in toy answers.</p>

<p>For this analysis, I reached for <a href="https://www.aclweb.org/anthology/W19-5301/" target="_blank">WMT19</a> outputs which give us a good mix of high and low-resource systems, including current large MT online engines. For WMT19 alone, I am looking at 14 translation directions and over 180 MT systems. It also gives me lots of test sets, results of human evaluation and even more historical data from previous years. We can assume that the best of the best is taking part in WMT. So much for the good part. We also have to be careful with overstating the results that we will gain from this. We are looking at only one domain (news) and WMT has a specific way of creating their test sets. There has been quite a bit of a debate concerning the quality of WMT test sets and the process involved. This needs to be emphasized as potential problems.</p>

<h2 id="on-the-lexical-diversity-of-wmt19-systems">On the lexical diversity of WMT19 systems</h2>

<p>The <a href="https://github.com/emjotde/diversity" target="_blank">GitHub repository</a> contains all the code required to repeat the experiments and to recreate the figures in this post. To compute TTR, I extract all continuous Unicode letter strings as tokens and lowercase them. Punctuation and numbers are ignored. For Chinese as a target language I separate them into single glyphs, that might be suboptimal.</p>

<p>So, let’s first look at TTR for all the WMT19 translation directions and the human-created references. Below (click for full size) you can see one box plot per translation direction. The red dot marks the LD of the human reference set. The box plot spans multiple MT systems from most to least lexically diverse as measured by TTR.</p>

<p><a href="/assets/images/blog/ld/fig1.ttr.png" target="_blank"><img src="/assets/images/blog/ld/fig1.ttr.png" alt="lexical diversity for WMT19" /></a></p>

<p>We can see immediately that in not a single case the human reference is the most lexically diverse (although it comes close a few times). There is always a couple of MT systems in the competition that display more lexical diversity than the human reference. I some cases the majority of MT systems is more diverse than the reference; for LT-EN, the reference is actually the lexically least diverse one. This is interesting. For WMT19 at least, it seems there would be no way to successfully tell apart MT from the human translated test set using TTR as a measure.</p>

<h2 id="does-lexical-diversity-correlate-with-human-perceived-quality">Does lexical diversity correlate with human-perceived quality?</h2>

<p>During the discussion time after the mentioned talks, the question of the meaning of lexical diversity was raised. Is higher LD actually better in general? Does lower LD stand for more consistency etc. Can we draw conclusions about lexical diversity and translation quality? Are more diverse MT outputs better than less diverse ones? Luckily, we can use WMT19 data to shed some light at that question as well. The system-level human judgments are available for download and we are looking at normalized z-Scores (x-axis) versus TTR (y-axis) for all language pairs in the figure below (click for full size).</p>

<p><a href="/assets/images/blog/ld/fig2.ttr.png" target="_blank"><img src="/assets/images/blog/ld/fig2.ttr.png" alt="correlation with human judgement" /></a></p>

<p>Green marks are MT systems, the red mark is the reference. For about half the translation directions the reference was included as a system to-be-judged by humans; for the rest the red mark is missing. We plot regression lines to indicate Pearson correlation between the two measures. Across all the language pairs it seems there is no visible correlation between LD and direct assessment of MT quality. Pearson correlation across all pairs is about 0.06, essentially random. For plots with the red marks of the human reference we can now clearly see that it is never the most lexically diverse. In the few cases where MT systems are close or better than the reference in terms of MT quality their lexical diversity can be higher and lower. As before, there are enough reasons to be critical about the WMT evaluation methods, but it seems that using LD for QE is not going to happen very soon (unless of course we discover that the human judgments are wrong).</p>

<h2 id="what-are-the-trends-over-time">What are the trends over time?</h2>

<p>Until now we have collected a number of negative results for our WMT19 data. However, we are using much stronger and technologically newer systems than the papers we discussed earlier. Maybe MT systems have only recently reached their high degree of lexical diversity?</p>

<p>Let’s take a look at a couple of years back: WMT19 is the first year where all the test sets are translated with the correct directionality. Between WMT15 and WMT18, half the test set would have the correct direction and half would have translationese source text with natural target text. The situation seems to be less clear before WMT15. Based on that, I separated the English-German test sets and the MT outputs from WMT15-18 into corresponding halves and calculate LD for MT vs translationese target text over the past five years, WMT15 to WMT19. During WMT15 only one system (<a href="https://www.aclweb.org/anthology/W15-3014/" target="_blank">Jean et al. 2015</a>) was a neural system, the rest was SMT or syntax-based. In the following years we can expect a mixed field of competitors, becoming fully neural towards WMT19. Looking at the figure below (click for full size) however we can see, that there is no trend. Even five years ago, LD would not have been a MT vs Human discriminator. The picture is similarly random for other languages (plots can be generated with my Makefile by replacing language ids).</p>

<p><a href="/assets/images/blog/ld/fig3.ttr.png" target="_blank"><img src="/assets/images/blog/ld/fig3.ttr.png" alt="Trend on natural reference" /></a></p>

<p>For the years WMT15 to WMT18 we also have the other half of the test sets, the halves with the translationese input and natural target text. Let’s have a look at the figure below (click for full size) what is going on there.</p>

<p><a href="/assets/images/blog/ld/fig3.ttr.inv.png" target="_blank"><img src="/assets/images/blog/ld/fig3.ttr.inv.png" alt="Trend on natural reference" /></a></p>

<p>Here we finally see something quite significant: over all four years the natural target is lexically more diverse than all the MT systems, by quite some margin. I verified that this is the case for a number more translation pairs and the results are the same. Unfortunately, in this setup we do not have human-created translations in the mix, so we can only compare apples to slightly different apples across the different time-based plots.</p>

<h2 id="conclusions">Conclusions?</h2>

<p>What can we conclude? A few things: For WMT data and systems specifically there seems to be no indication that WMT test sets created by humans are lexically more diverse than WMT systems; they actually seem to fall into the same ballpark. There seems to be no larger difference or change in trend across the years while moving from SMT to NMT. There seems to be no meaningful correlation between the lexical richness of MT and its human-judged quality, whether in source-based or reference-based human-eval scenarios.</p>

<p>Natural text is clearly more diverse than MT output, but this comes with a BIG gotcha for WMT: These MT systems translated from source translationese which is likely to be less diverse than natural text, so that would possibly result in a double loss of lexical richness, first by human, next by machine. It might be unfair to judge the MT systems based on that.</p>

<p>So, can LD be useful for anything? Hard to say for now. I see some hope for identifying natural text versus translationese, whether it comes from machines or humans.</p>

<p>As for the main question from the post title: I think we need to be precise that the lexical diversity of WMT outputs is similar to that of WMT test set references. There is the very real possibility that WMT translations are of a lower quality than other translations although they have been ordered from professional agencies etc. I have no evidence for or against that. However, these results also mean that claims of generally lower lexical diversity for MT are potentially doubtful. For one of the most important and biggest MT competitions and its test sets they would be wrong.</p>

<div class="comments">
  <h4 class="comments-header">Comments</h4>
  <p class="comments-help">
  To comment, you must sign in to your GitHub account below and authorize the
  <a href="https://utteranc.es" target="_blank">utterances</a> app to post in
  your behalf, or post on
  <a href="https://github.com/marian-nmt/marian-nmt.github.io/issues/26" target="_blank">the GitHub issue #26</a> directly.
  </p>
</div>
<script src="https://utteranc.es/client.js" repo="marian-nmt/marian-nmt.github.io" issue-number="26" crossorigin="anonymous" theme="github-light" async="">

</script>


            </div><!--//content-inner-->
          </div><!--//doc-content-->

          <div class="doc-sidebar hidden-xs">
            <nav id="doc-nav"></nav>
          </div><!--//doc-sidebar-->

        </div><!--//doc-body-->

      </div><!--//container-->
    </div><!--//doc-wrapper-->

    </div><!--//page-wrapper-->

    <footer id="footer" class="footer text-center">
  <div class="container">
    <p>
     Marian - an efficient Neural Machine Translation framework written in pure C++.</br>
      Mainly developed at Microsoft Translator and at the University of Edinburgh.
    </p>
    <p><a href="https://github.com/marian-nmt/marian#marian">Marian</a> is licensed under the <a href="https://github.com/marian-nmt/marian/blob/master/LICENSE.md">MIT license</a>.</p>
    <p><small class="copyright footnote">Based on the theme PrettyDocs designed by <a href="http://themes.3rdwavemedia.com/" targe="_blank">Xiaoying Riley</a> with modifications.</small></p>
  </div><!--//container-->
</footer><!--//footer-->

    <!-- Main Javascript -->
<script type="text/javascript"> localStorage.clear();</script>

<script type="text/javascript" src="/assets/plugins/jquery-1.12.3.min.js"></script>
<script type="text/javascript" src="/assets/plugins/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script>
<script type="text/javascript" src="/assets/plugins/jquery-match-height/jquery.matchHeight-min.js"></script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/javascript" src="/assets/js/main.js"></script>
<script type="text/javascript" src="/assets/js/toc.js"></script>


  </body>
</html>
