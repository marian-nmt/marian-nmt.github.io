<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en">
<!--<![endif]-->

  <head>
  <title>
    
    Marian :: Winning system of the WMT 2016 APE shared task
    
  </title>
  <!-- Meta -->
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Fast Neural Machine Translation in C++">

  <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
  <!-- Global CSS -->
  <link rel="stylesheet" href="/assets/plugins/bootstrap/css/bootstrap.min.css">
  <!-- Plugins CSS -->
  <link rel="stylesheet" href="/assets/plugins/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="/assets/css/pygments/github.css">

  <!-- Theme CSS -->
  <link id="theme-style" rel="stylesheet" href="/assets/css/styles.css">
  <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->

  <link rel="stylesheet" href="/assets/plugins/github-fork-ribbon-css/gh-fork-ribbon.css" />
  <!--[if lt IE 9]>
    <link rel="stylesheet" href="/assets/plugins/github-fork-ribbon-css/gh-fork-ribbon.ie.css" />
  <![endif]-->

  
</head>


  <body class="body-blue">
    <a class="github-fork-ribbon" href="https://github.com/marian-nmt/marian" title="Fork me on GitHub">Fork me on GitHub</a>

    <div class="page-wrapper">

    <header id="header" class="header">
  <div class="container">
    <div class="branding">
      <h1 class="logo">
        <a href="/">
          <span aria-hidden="true" class="icon_documents_alt icon"></span>
          <span class="text-highlight">Marian</span><span class="text-bold">NMT</span>
        </a>
      </h1>
      <p class="description">Fast Neural Machine Translation in C++</p>
    </div><!--//branding-->

    <ol class="breadcrumb">


 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 
 <li>
   <a class="page-link" href="/quickstart/">Quick start</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/features/">Features &amp; Benchmarks</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/docs/">Documentation</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/examples/">Examples &amp; Use cases</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/faq">Google group</a>
 </li>
 

 
 <li>
   <a class="page-link" href="/publications/">Publications</a>
 </li>
 

</ol>


  </div><!--//container-->
</header><!--//header-->


    <div class="doc-wrapper">
      <div class="container">

        <div id="doc-header" class="doc-header text-center">
          <h1 class="doc-title">
            
            <i class="icon fa fa-cogs }}"></i>
            
            Winning system of the WMT 2016 APE shared task
          </h1>
          <div class="meta">
            <i class="fa fa-clock-o"></i>
            Last updated: 06 June 2017
          </div>
        </div><!--//doc-header-->

        <div class="doc-body">
          <div class="doc-content">
            <div class="content-inner">

              <p><strong>Works with commit: 3833669</strong></p>

<p>This page provides data and model files for our shared task winning APE system described in <a href="http://www.aclweb.org/anthology/W16-2378">Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing</a>. If you use any of the data, systems or ideas, please cite:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>@InProceedings{junczysdowmunt-grundkiewicz:2016:WMT,
   author    = {Junczys-Dowmunt, Marcin  and  Grundkiewicz, Roman},
   title     = {Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing},
   booktitle = {Proceedings of the First Conference on Machine Translation},
   month     = {August},
   year      = {2016},
   address   = {Berlin, Germany},
   publisher = {Association for Computational Linguistics},
   pages     = {751--758},
   url       = {http://www.aclweb.org/anthology/W16-2378}
}
</code></pre>
</div>

<h2 id="artificially-created-data">Artificially created data</h2>
<p><a href="http://odkrywka.wmi.amu.edu.pl/static/data/ape/data.tgz">Download the training data</a> (514M)</p>

<p>This file contains the artificially generated post-editing triplets described in Table 1 of the paper. “4M” is the larger set denoted as “round-trip.n10” in that table, 500K is the smaller set denoted as “round-trip.n1”. The 20 times oversampled original training data for the shared task is not included, but can be obtained from the original <a href="http://www.statmt.org/wmt16/ape-task.html">shared task page</a>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>data
├── 4M
│   ├── 4M.mt
│   ├── 4M.pe
│   └── 4M.src
└── 500K
    ├── 500K.mt
    ├── 500K.pe
    └── 500K.src
</code></pre>
</div>

<h2 id="models-and-config-files">Models and config files</h2>
<p><a href="http://odkrywka.wmi.amu.edu.pl/static/data/ape/system.tgz">Download the systems</a> (2.7G)</p>

<p>We also provide the complete primary system and two contrastive variants. To create the submitted output, locate the <code class="highlighter-rouge">Makefile</code> and provide the path to the main directory of your working Marian tool (latest master, see <a href="https://github.com/marian-nmt/marian/blob/master/README.md">Readme</a>) in the following line:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>AMUNMT=/home/marcinj/Badania/marian 
</code></pre>
</div>

<p>Next type <code class="highlighter-rouge">make</code>. The included files should provide all input files, model files and scripts to produce our exact submission. You may need to change the number of GPU devices, as the original configs assume three GPUs. In the end you should see the three submission files:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>AMU_ensemble8-mt+src_PRIMARY
AMU_ensemble4-mt_CONTRASTIVE
AMU_ensemble4-src_CONTRASTIVE
</code></pre>
</div>

<p>The configuration file for the best ensemble <code class="highlighter-rouge">models/configs/mtsrc-pe.ensemble.ape.tuned.yml</code> has been included below. It assumes the presence and availability of three GPUs in the line <code class="highlighter-rouge">devices: [0, 1, 2]</code>, you want to change it to one device by <code class="highlighter-rouge">devices: [0]</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code># amunn config file

relative-paths: yes

# Scorer configuration
scorers:
  F0:
    type: Nematus
    path: ../mt-pe/model.iter260000.npz
  F1:
    type: Nematus
    path: ../mt-pe/model.iter270000.npz
  F2:
    type: Nematus
    path: ../mt-pe/model.iter280000.npz
  F3:
    type: Nematus
    path: ../mt-pe/model.iter290000.npz
  F4:
    type: Nematus
    path: ../src-pe/model.iter340000.npz
    tab: 1
  F5:
    type: Nematus
    path: ../src-pe/model.iter350000.npz
    tab: 1
  F6:
    type: Nematus
    path: ../src-pe/model.iter360000.npz
    tab: 1
  F7:
    type: Nematus
    path: ../src-pe/model.iter370000.npz
    tab: 1
  F8:
    type: APE

source-vocab:
  - ../mt-pe/vocab.mt.json
  - ../src-pe/vocab.src.json
target-vocab: ../mt-pe/vocab.pe.json

weights:
  F0: 0.0679875234050288
  F1: 0.136272622440232
  F2: 0.0447424881348462
  F3: 0.0505810091549122
  F4: 0.119029214497868
  F5: -0.0291262004966649
  F6: -0.0348248568202612
  F7: 0.131424048800743
  F8: 0.386012036249443

beam-size: 12
normalize: yes
n-best: no

devices: [0, 1, 2]
threads-per-device: 1
</code></pre>
</div>

<p>In the future we will provide more hints on how to train a similar system. Currently we supply the following files:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>system
├── data
│   ├── de.bpe
│   ├── en.bpe
│   ├── true.de
│   └── true.en
├── Makefile
├── models
│   ├── configs
│   │   ├── mt-pe.ensemble4.tuned.yml
│   │   ├── mtsrc-pe.ensemble.ape.tuned.yml
│   │   └── src-pe.ensemble4.yml
│   ├── mt-pe
│   │   ├── model.iter260000.npz
│   │   ├── model.iter270000.npz
│   │   ├── model.iter280000.npz
│   │   ├── model.iter290000.npz
│   │   ├── vocab.mt.json
│   │   └── vocab.pe.json
│   └── src-pe
│       ├── model.iter340000.npz
│       ├── model.iter350000.npz
│       ├── model.iter360000.npz
│       ├── model.iter370000.npz
│       ├── vocab.pe.json
│       └── vocab.src.json
├── scripts
│   ├── apply_bpe.py
│   ├── deescape-special-chars.perl
│   ├── detruecase.perl
│   ├── escape-special-chars.perl
│   ├── prepare_submission.py
│   └── truecase.perl
└── test
    ├── test.mt
    └── test.src
</code></pre>
</div>

<p>where <code class="highlighter-rouge">data</code> contains truecasing models and BPE codes. <code class="highlighter-rouge">models/configs</code> provides the configuration files for <code class="highlighter-rouge">amun</code> to load the model ensembles located in <code class="highlighter-rouge">mt-pe</code> (monolingual model, trained on MT-output and post-editing data) and <code class="highlighter-rouge">src-pe</code> (bilingual model, trained on source and post-editing data). <code class="highlighter-rouge">test</code> contains the blind test set, ground truth and evaluation scripts are again available from the <a href="http://www.statmt.org/wmt16/ape-task.html">shared task page</a>.</p>


            </div><!--//content-inner-->
          </div><!--//doc-content-->

          <div class="doc-sidebar hidden-xs">
            <nav id="doc-nav"></nav>
          </div><!--//doc-sidebar-->

        </div><!--//doc-body-->

      </div><!--//container-->
    </div><!--//doc-wrapper-->

    </div><!--//page-wrapper-->

    <footer id="footer" class="footer text-center">
  <div class="container">
    <p>
     Marian - an efficient Neural Machine Translation framework written in pure C++.</br>
      Mainly developed at the Adam Mickiewicz University in Poznań and at the University of Edinburgh.
    </p>
    <p><a href="https://github.com/marian-nmt/marian">Marian</a> is licensed under the <a href="https://github.com/marian-nmt/marian/LICENSE">MIT license</a>.</p>
    <small class="copyright">Based on the theme PrettyDocs designed by <a href="http://themes.3rdwavemedia.com/" targe="_blank">Xiaoying Riley</a> with modifications.</small>
  </div><!--//container-->
</footer><!--//footer-->

    <!-- Main Javascript -->
<script type="text/javascript"> localStorage.clear();</script>

<script type="text/javascript" src="/assets/plugins/jquery-1.12.3.min.js"></script>
<script type="text/javascript" src="/assets/plugins/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="/assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script>
<script type="text/javascript" src="/assets/plugins/jquery-match-height/jquery.matchHeight-min.js"></script>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<script type="text/javascript" src="/assets/js/main.js"></script>
<script type="text/javascript" src="/assets/js/toc.js"></script>


  </body>
</html>
